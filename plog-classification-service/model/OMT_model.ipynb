{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Material Type (OMT) Classifier, based on OpenAI's CLIP Model\n",
    "Source: https://openai.com/research/clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from model_functions import *\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df_dataset = load_from_pickle(dataset_file)\n",
    "# Take 10% of stratified samples for zero-shot classification testing\n",
    "_x_train, zs_x, _y_train, zs_y = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.01, stratify=df_dataset['Material Class'], random_state=9876)\n",
    "# 80-20 Train-Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.2, stratify=df_dataset['Material Class'], random_state=1234)\n",
    "\n",
    "# Initialise material classes\n",
    "material_classes = [i.lower() for i in material_class_mapping.values()]\n",
    "for idx, i in enumerate(material_classes):\n",
    "    if(i == 'others'):\n",
    "        material_classes[idx] = \"anything other than paper, plastic, glass, or metal\"\n",
    "\n",
    "# Preparations for model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "text_prompt = torch.cat([clip.tokenize(f\"a photo of an object made of {c}\") for c in material_classes]).to(device)\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device, download_root=MODEL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 427,616,513\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.720164609053498\n",
      "Precision: 0.734947393591583\n",
      "Recall: 0.7138424998330328\n",
      "F1 Score: 0.703695785990944\n",
      "Matthews Correlation Coefficient (MCC): 0.640289920044027\n",
      "Cohen's Kappa: 0.6349013455887227\n",
      "Hamming Loss: 0.27983539094650206\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70  9  0  0 14]\n",
      " [ 4 35  6  0  1]\n",
      " [ 2  2 26  0  0]\n",
      " [ 5  0  8 19  0]\n",
      " [ 1  5 11  0 25]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80        93\n",
      "           1       0.69      0.76      0.72        46\n",
      "           2       0.51      0.87      0.64        30\n",
      "           3       1.00      0.59      0.75        32\n",
      "           4       0.62      0.60      0.61        42\n",
      "\n",
      "    accuracy                           0.72       243\n",
      "   macro avg       0.73      0.71      0.70       243\n",
      "weighted avg       0.76      0.72      0.73       243\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initial Performance \"\"\"\n",
    "# Get model specifications\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size, end='\\n\\n')\n",
    "\n",
    "# Initialise predictions\n",
    "zs_y_pred = []\n",
    "for current_image in zs_x:\n",
    "    # Initialise image\n",
    "    image = preprocess(Image.open(current_image)).unsqueeze(0).to(device)\n",
    "\n",
    "    # Classify image's material type\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text_prompt)\n",
    "        \n",
    "        # logits_per_image, logits_per_text = model(image, text_prompt)\n",
    "        # probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        values, indices = similarity[0].topk(len(material_classes))\n",
    "\n",
    "        # Add result to predictions\n",
    "        zs_y_pred.append(int(indices[0]))\n",
    "\n",
    "        # Print the result\n",
    "        # print(\"\\nTop predictions:\\n\")\n",
    "        # for value, index in zip(values, indices):\n",
    "        #     print(f\"{material_classes[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "\n",
    "# Get model performance\n",
    "results = multi_class_metrics(list(zs_y), zs_y_pred)\n",
    "accuracy = results['accuracy']\n",
    "precision = results['precision']\n",
    "recall = results['recall']\n",
    "f1 = results['f1']\n",
    "mcc = results['mcc']\n",
    "kappa = results['kappa']\n",
    "hamming_loss_val = results['hamming_loss_val']\n",
    "cm = results['cm']\n",
    "class_report = results['class_report']\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "print(\"Cohen's Kappa:\", kappa)\n",
    "print(\"Hamming Loss:\", hamming_loss_val, end='\\n\\n')\n",
    "print(\"Confusion Matrix:\\n\", cm, end=\"\\n\\n\")\n",
    "print(\"Classification Report:\\n\", class_report, end=\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
