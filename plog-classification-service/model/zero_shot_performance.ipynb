{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Material Type (OMT) Classifier, based on OpenAI's CLIP Model\n",
    "Source: https://openai.com/research/clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, matthews_corrcoef, cohen_kappa_score, hamming_loss\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df_dataset = load_from_pickle(dataset_file)\n",
    "# Take 10% of stratified samples for zero-shot classification testing\n",
    "_x_train, zs_x, _y_train, zs_y = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.1, stratify=df_dataset['Material Class'], random_state=9876)\n",
    "# 80-20 Train-Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.2, stratify=df_dataset['Material Class'], random_state=1234)\n",
    "\n",
    "# Initialise material classes\n",
    "material_classes = [i.lower() for i in material_class_mapping.values()]\n",
    "for idx, i in enumerate(material_classes):\n",
    "    if(i == 'others'):\n",
    "        material_classes[idx] = \"anything other than paper, plastic, glass, or metal\"\n",
    "\n",
    "# Preparations for model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "text_prompt = torch.cat([clip.tokenize(f\"photo of an object made of {c}\") for c in material_classes]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance of available models\n",
    "for current_model in clip.available_models(): \n",
    "    # Initialise model\n",
    "    model, preprocess = clip.load(current_model, device=device, download_root=MODEL_FOLDER)\n",
    "\n",
    "    # Get model specifications\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "    \n",
    "    print(\"Model:\", current_model)\n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    print(\"Input resolution:\", input_resolution)\n",
    "    print(\"Context length:\", context_length)\n",
    "    print(\"Vocab size:\", vocab_size, end='\\n\\n')\n",
    "    \n",
    "    # Initialise predictions\n",
    "    zs_y_pred = []\n",
    "    for current_image in zs_x:\n",
    "        # Initialise image\n",
    "        image = preprocess(Image.open(current_image)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Classify image's material type\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(text_prompt)\n",
    "            \n",
    "            # logits_per_image, logits_per_text = model(image, text_prompt)\n",
    "            # probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "            values, indices = similarity[0].topk(len(material_classes))\n",
    "\n",
    "            # Add result to predictions\n",
    "            zs_y_pred.append(int(indices[0]))\n",
    "\n",
    "            # Print the result\n",
    "            # print(\"\\nTop predictions:\\n\")\n",
    "            # for value, index in zip(values, indices):\n",
    "            #     print(f\"{material_classes[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "\n",
    "    # Get model performance\n",
    "    list_zs_y = list(zs_y)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(list_zs_y, zs_y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC)\n",
    "    mcc = matthews_corrcoef(list_zs_y, zs_y_pred)\n",
    "    print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(list_zs_y, zs_y_pred)\n",
    "    print(\"Cohen's Kappa:\", kappa)\n",
    "\n",
    "    # Hamming Loss\n",
    "    hamming_loss_val = hamming_loss(list_zs_y, zs_y_pred)\n",
    "    print(\"Hamming Loss:\", hamming_loss_val, end='\\n\\n')\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(list_zs_y, zs_y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm, end=\"\\n\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(list_zs_y, zs_y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on 10% Stratified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Model: RN50\n",
    "Model parameters: 102,007,137\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.459983498349835\n",
    "Precision: 0.5364220929770019\n",
    "Recall: 0.38003848168448484\n",
    "F1 Score: 0.3680587218509033\n",
    "Matthews Correlation Coefficient (MCC): 0.25340113747196713\n",
    "Cohen's Kappa: 0.23193098306528914\n",
    "Hamming Loss: 0.540016501650165\n",
    "\n",
    "Confusion Matrix:\n",
    "[[698 122  77   1  25]\n",
    " [227 173  51   0   6]\n",
    " [127   5 159   7   0]\n",
    " [216   1  61  42   2]\n",
    " [267  26  83   5  43]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.45      0.76      0.57       923\n",
    "           1       0.53      0.38      0.44       457\n",
    "           2       0.37      0.53      0.44       298\n",
    "           3       0.76      0.13      0.22       322\n",
    "           4       0.57      0.10      0.17       424\n",
    "\n",
    "    accuracy                           0.46      2424\n",
    "   macro avg       0.54      0.38      0.37      2424\n",
    "weighted avg       0.52      0.46      0.41      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: RN101\n",
    "Model parameters: 119,688,033\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.43853135313531355\n",
    "Precision: 0.5527112807582848\n",
    "Recall: 0.41461532266208617\n",
    "F1 Score: 0.3941133714670186\n",
    "Matthews Correlation Coefficient (MCC): 0.24808290524134521\n",
    "Cohen's Kappa: 0.2311673445189052\n",
    "Hamming Loss: 0.5614686468646864\n",
    "\n",
    "Confusion Matrix:\n",
    "[[569  41 234   6  73]\n",
    " [298  84  69   2   4]\n",
    " [ 57   1 237   3   0]\n",
    " [135   2  88  93   4]\n",
    " [250   7  85   2  80]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.43      0.62      0.51       923\n",
    "           1       0.62      0.18      0.28       457\n",
    "           2       0.33      0.80      0.47       298\n",
    "           3       0.88      0.29      0.43       322\n",
    "           4       0.50      0.19      0.27       424\n",
    "\n",
    "    accuracy                           0.44      2424\n",
    "   macro avg       0.55      0.41      0.39      2424\n",
    "weighted avg       0.53      0.44      0.41      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x4\n",
    "Model parameters: 178,300,601\n",
    "Input resolution: 288\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.4236798679867987\n",
    "Precision: 0.48681441780354745\n",
    "Recall: 0.4645814783022167\n",
    "F1 Score: 0.4189558129951056\n",
    "Matthews Correlation Coefficient (MCC): 0.2785911295413147\n",
    "Cohen's Kappa: 0.267045705425068\n",
    "Hamming Loss: 0.5763201320132013\n",
    "\n",
    "Confusion Matrix:\n",
    "[[265 118 281   3 256]\n",
    " [ 48 339  56   5   9]\n",
    " [ 33   7 244  12   2]\n",
    " [147   4  93  71   7]\n",
    " [149  46 120   1 108]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.41      0.29      0.34       923\n",
    "           1       0.66      0.74      0.70       457\n",
    "           2       0.31      0.82      0.45       298\n",
    "           3       0.77      0.22      0.34       322\n",
    "           4       0.28      0.25      0.27       424\n",
    "\n",
    "    accuracy                           0.42      2424\n",
    "   macro avg       0.49      0.46      0.42      2424\n",
    "weighted avg       0.47      0.42      0.41      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x16\n",
    "Model parameters: 290,979,217\n",
    "Input resolution: 384\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.3778877887788779\n",
    "Precision: 0.6005714234807596\n",
    "Recall: 0.2875830346805791\n",
    "F1 Score: 0.2680951382913359\n",
    "Matthews Correlation Coefficient (MCC): 0.10396886235842223\n",
    "Cohen's Kappa: 0.08371582946158096\n",
    "Hamming Loss: 0.6221122112211221\n",
    "\n",
    "Confusion Matrix:\n",
    "[[672   2 228   2  19]\n",
    " [338  54  51   0  14]\n",
    " [170   0 126   1   1]\n",
    " [276   0  22  24   0]\n",
    " [376   1   6   1  40]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.37      0.73      0.49       923\n",
    "           1       0.95      0.12      0.21       457\n",
    "           2       0.29      0.42      0.34       298\n",
    "           3       0.86      0.07      0.14       322\n",
    "           4       0.54      0.09      0.16       424\n",
    "\n",
    "    accuracy                           0.38      2424\n",
    "   macro avg       0.60      0.29      0.27      2424\n",
    "weighted avg       0.56      0.38      0.31      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x64\n",
    "Model parameters: 623,258,305\n",
    "Input resolution: 448\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.5107260726072608\n",
    "Precision: 0.6150121280504154\n",
    "Recall: 0.503943698798375\n",
    "F1 Score: 0.4940139667238478\n",
    "Matthews Correlation Coefficient (MCC): 0.36780074396645157\n",
    "Cohen's Kappa: 0.3562257593536424\n",
    "Hamming Loss: 0.4892739273927393\n",
    "\n",
    "Confusion Matrix:\n",
    "[[507  92 301   4  19]\n",
    " [ 93 289  71   0   4]\n",
    " [ 60   9 214  15   0]\n",
    " [151   6  54 110   1]\n",
    " [123 126  55   2 118]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.54      0.55      0.55       923\n",
    "           1       0.55      0.63      0.59       457\n",
    "           2       0.31      0.72      0.43       298\n",
    "           3       0.84      0.34      0.49       322\n",
    "           4       0.83      0.28      0.42       424\n",
    "\n",
    "    accuracy                           0.51      2424\n",
    "   macro avg       0.62      0.50      0.49      2424\n",
    "weighted avg       0.61      0.51      0.51      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-B/32\n",
    "Model parameters: 151,277,313\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.5198019801980198\n",
    "Precision: 0.5566003027870373\n",
    "Recall: 0.5115291964599042\n",
    "F1 Score: 0.5088150348719772\n",
    "Matthews Correlation Coefficient (MCC): 0.36312681718413553\n",
    "Cohen's Kappa: 0.35875201985422955\n",
    "Hamming Loss: 0.4801980198019802\n",
    "\n",
    "Confusion Matrix:\n",
    "[[515 195 110   0 103]\n",
    " [ 65 308  61   3  20]\n",
    " [ 79  12 191  14   2]\n",
    " [150   2  27 140   3]\n",
    " [190  84  37   7 106]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.52      0.56      0.54       923\n",
    "           1       0.51      0.67      0.58       457\n",
    "           2       0.45      0.64      0.53       298\n",
    "           3       0.85      0.43      0.58       322\n",
    "           4       0.45      0.25      0.32       424\n",
    "\n",
    "    accuracy                           0.52      2424\n",
    "   macro avg       0.56      0.51      0.51      2424\n",
    "weighted avg       0.54      0.52      0.51      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-B/16\n",
    "Model parameters: 149,620,737\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.49834983498349833\n",
    "Precision: 0.5593171334247528\n",
    "Recall: 0.4970808217221248\n",
    "F1 Score: 0.48833988282391905\n",
    "Matthews Correlation Coefficient (MCC): 0.3454062610394499\n",
    "Cohen's Kappa: 0.3408978292174629\n",
    "Hamming Loss: 0.5016501650165016\n",
    "\n",
    "Confusion Matrix:\n",
    "[[483  27  93   0 320]\n",
    " [126 246  68   1  16]\n",
    " [ 48  14 223  10   3]\n",
    " [121   0  97  96   8]\n",
    " [108  97  57   2 160]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.55      0.52      0.53       923\n",
    "           1       0.64      0.54      0.59       457\n",
    "           2       0.41      0.75      0.53       298\n",
    "           3       0.88      0.30      0.45       322\n",
    "           4       0.32      0.38      0.34       424\n",
    "\n",
    "    accuracy                           0.50      2424\n",
    "   macro avg       0.56      0.50      0.49      2424\n",
    "weighted avg       0.55      0.50      0.50      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-L/14\n",
    "Model parameters: 427,616,513\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.6621287128712872\n",
    "Precision: 0.6671066030427073\n",
    "Recall: 0.6464374130645891\n",
    "F1 Score: 0.6345731510632313\n",
    "Matthews Correlation Coefficient (MCC): 0.5628138868486012\n",
    "Cohen's Kappa: 0.557143634710465\n",
    "Hamming Loss: 0.3378712871287129\n",
    "\n",
    "Confusion Matrix:\n",
    "[[683  81  16   2 141]\n",
    " [ 56 334  65   0   2]\n",
    " [ 27  13 246  12   0]\n",
    " [ 72   2  73 173   2]\n",
    " [ 34  82 134   5 169]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.78      0.74      0.76       923\n",
    "           1       0.65      0.73      0.69       457\n",
    "           2       0.46      0.83      0.59       298\n",
    "           3       0.90      0.54      0.67       322\n",
    "           4       0.54      0.40      0.46       424\n",
    "\n",
    "    accuracy                           0.66      2424\n",
    "   macro avg       0.67      0.65      0.63      2424\n",
    "weighted avg       0.69      0.66      0.66      2424\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-L/14@336px\n",
    "Model parameters: 427,944,193\n",
    "Input resolution: 336\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.6542904290429042\n",
    "Precision: 0.663429523779947\n",
    "Recall: 0.627868365041197\n",
    "F1 Score: 0.6192232789472756\n",
    "Matthews Correlation Coefficient (MCC): 0.5501572631477752\n",
    "Cohen's Kappa: 0.5438385557779997\n",
    "Hamming Loss: 0.3457095709570957\n",
    "\n",
    "Confusion Matrix:\n",
    "[[708  82   8   1 124]\n",
    " [ 65 325  65   0   2]\n",
    " [ 36  12 238  12   0]\n",
    " [ 81   2  79 160   0]\n",
    " [ 41  75 150   3 155]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.76      0.77      0.76       923\n",
    "           1       0.66      0.71      0.68       457\n",
    "           2       0.44      0.80      0.57       298\n",
    "           3       0.91      0.50      0.64       322\n",
    "           4       0.55      0.37      0.44       424\n",
    "\n",
    "    accuracy                           0.65      2424\n",
    "   macro avg       0.66      0.63      0.62      2424\n",
    "weighted avg       0.68      0.65      0.65      2424\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on 1% Stratified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Model: RN50\n",
    "Model parameters: 102,007,137\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.448559670781893\n",
    "Precision: 0.583571768469864\n",
    "Recall: 0.3751343251185467\n",
    "F1 Score: 0.37071455515687757\n",
    "Matthews Correlation Coefficient (MCC): 0.23762702989158305\n",
    "Cohen's Kappa: 0.2213959494034098\n",
    "Hamming Loss: 0.551440329218107\n",
    "\n",
    "Confusion Matrix:\n",
    "[[65 15 12  0  1]\n",
    " [23 20  3  0  0]\n",
    " [14  1 14  1  0]\n",
    " [18  1  8  5  0]\n",
    " [26  4  7  0  5]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.45      0.70      0.54        93\n",
    "           1       0.49      0.43      0.46        46\n",
    "           2       0.32      0.47      0.38        30\n",
    "           3       0.83      0.16      0.26        32\n",
    "           4       0.83      0.12      0.21        42\n",
    "\n",
    "    accuracy                           0.45       243\n",
    "   macro avg       0.58      0.38      0.37       243\n",
    "weighted avg       0.56      0.45      0.41       243\n",
    "\n",
    "\n",
    "\n",
    "Model: RN101\n",
    "Model parameters: 119,688,033\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.4732510288065844\n",
    "Precision: 0.6328468406593407\n",
    "Recall: 0.4481032525212048\n",
    "F1 Score: 0.4353587588881706\n",
    "Matthews Correlation Coefficient (MCC): 0.2964528719346169\n",
    "Cohen's Kappa: 0.27898189573239984\n",
    "Hamming Loss: 0.5267489711934157\n",
    "\n",
    "Confusion Matrix:\n",
    "[[59 10 22  0  2]\n",
    " [25 12  9  0  0]\n",
    " [ 4  1 25  0  0]\n",
    " [15  1  8  8  0]\n",
    " [25  0  6  0 11]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.46      0.63      0.53        93\n",
    "           1       0.50      0.26      0.34        46\n",
    "           2       0.36      0.83      0.50        30\n",
    "           3       1.00      0.25      0.40        32\n",
    "           4       0.85      0.26      0.40        42\n",
    "\n",
    "    accuracy                           0.47       243\n",
    "   macro avg       0.63      0.45      0.44       243\n",
    "weighted avg       0.59      0.47      0.45       243\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x4\n",
    "Model parameters: 178,300,601\n",
    "Input resolution: 288\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.4444444444444444\n",
    "Precision: 0.5236139332365748\n",
    "Recall: 0.48317045682228005\n",
    "F1 Score: 0.4459617423004151\n",
    "Matthews Correlation Coefficient (MCC): 0.30142422420908876\n",
    "Cohen's Kappa: 0.2899196952314985\n",
    "Hamming Loss: 0.5555555555555556\n",
    "\n",
    "Confusion Matrix:\n",
    "[[29 11 31  0 22]\n",
    " [ 9 35  1  0  1]\n",
    " [ 4  1 24  1  0]\n",
    " [13  0 10  9  0]\n",
    " [13  6 12  0 11]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.43      0.31      0.36        93\n",
    "           1       0.66      0.76      0.71        46\n",
    "           2       0.31      0.80      0.44        30\n",
    "           3       0.90      0.28      0.43        32\n",
    "           4       0.32      0.26      0.29        42\n",
    "\n",
    "    accuracy                           0.44       243\n",
    "   macro avg       0.52      0.48      0.45       243\n",
    "weighted avg       0.50      0.44      0.43       243\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x16\n",
    "Model parameters: 290,979,217\n",
    "Input resolution: 384\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.39094650205761317\n",
    "Precision: 0.7298524087997772\n",
    "Recall: 0.29988821545448474\n",
    "F1 Score: 0.30113976304214096\n",
    "Matthews Correlation Coefficient (MCC): 0.11915305898735758\n",
    "Cohen's Kappa: 0.09360350824134278\n",
    "Hamming Loss: 0.6090534979423868\n",
    "\n",
    "Confusion Matrix:\n",
    "[[68  0 25  0  0]\n",
    " [36  8  2  0  0]\n",
    " [19  0 11  0  0]\n",
    " [27  0  0  5  0]\n",
    " [39  0  0  0  3]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.36      0.73      0.48        93\n",
    "           1       1.00      0.17      0.30        46\n",
    "           2       0.29      0.37      0.32        30\n",
    "           3       1.00      0.16      0.27        32\n",
    "           4       1.00      0.07      0.13        42\n",
    "\n",
    "    accuracy                           0.39       243\n",
    "   macro avg       0.73      0.30      0.30       243\n",
    "weighted avg       0.67      0.39      0.34       243\n",
    "\n",
    "\n",
    "\n",
    "Model: RN50x64\n",
    "Model parameters: 623,258,305\n",
    "Input resolution: 448\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.5267489711934157\n",
    "Precision: 0.6232332944832945\n",
    "Recall: 0.5095527783343352\n",
    "F1 Score: 0.49698702494362906\n",
    "Matthews Correlation Coefficient (MCC): 0.3827235763528328\n",
    "Cohen's Kappa: 0.37162709120345394\n",
    "Hamming Loss: 0.4732510288065844\n",
    "\n",
    "Confusion Matrix:\n",
    "[[56  9 25  1  2]\n",
    " [10 29  7  0  0]\n",
    " [ 7  0 22  1  0]\n",
    " [15  2  4 11  0]\n",
    " [11 15  6  0 10]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.57      0.60      0.58        93\n",
    "           1       0.53      0.63      0.57        46\n",
    "           2       0.34      0.73      0.47        30\n",
    "           3       0.85      0.34      0.49        32\n",
    "           4       0.83      0.24      0.37        42\n",
    "\n",
    "    accuracy                           0.53       243\n",
    "   macro avg       0.62      0.51      0.50       243\n",
    "weighted avg       0.61      0.53      0.52       243\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-B/32\n",
    "Model parameters: 151,277,313\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.5596707818930041\n",
    "Precision: 0.6148514851485148\n",
    "Recall: 0.5433259032925932\n",
    "F1 Score: 0.5445632206500818\n",
    "Matthews Correlation Coefficient (MCC): 0.4163739149401716\n",
    "Cohen's Kappa: 0.41027443864821955\n",
    "Hamming Loss: 0.4403292181069959\n",
    "\n",
    "Confusion Matrix:\n",
    "[[58 18  8  0  9]\n",
    " [ 6 32  7  0  1]\n",
    " [ 8  2 20  0  0]\n",
    " [14  1  2 15  0]\n",
    " [15 11  5  0 11]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.57      0.62      0.60        93\n",
    "           1       0.50      0.70      0.58        46\n",
    "           2       0.48      0.67      0.56        30\n",
    "           3       1.00      0.47      0.64        32\n",
    "           4       0.52      0.26      0.35        42\n",
    "\n",
    "    accuracy                           0.56       243\n",
    "   macro avg       0.61      0.54      0.54       243\n",
    "weighted avg       0.60      0.56      0.55       243\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-B/16\n",
    "Model parameters: 149,620,737\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.51440329218107\n",
    "Precision: 0.5705212894514913\n",
    "Recall: 0.5004149135109864\n",
    "F1 Score: 0.5024798569075044\n",
    "Matthews Correlation Coefficient (MCC): 0.3559923760937538\n",
    "Cohen's Kappa: 0.3533444589779442\n",
    "Hamming Loss: 0.48559670781893005\n",
    "\n",
    "Confusion Matrix:\n",
    "[[52  5  4  0 32]\n",
    " [12 29  4  0  1]\n",
    " [ 8  2 20  0  0]\n",
    " [14  0  8 10  0]\n",
    " [11  9  7  1 14]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.54      0.56      0.55        93\n",
    "           1       0.64      0.63      0.64        46\n",
    "           2       0.47      0.67      0.55        30\n",
    "           3       0.91      0.31      0.47        32\n",
    "           4       0.30      0.33      0.31        42\n",
    "\n",
    "    accuracy                           0.51       243\n",
    "   macro avg       0.57      0.50      0.50       243\n",
    "weighted avg       0.56      0.51      0.51       243\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-L/14\n",
    "Model parameters: 427,616,513\n",
    "Input resolution: 224\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.6831275720164609\n",
    "Precision: 0.7025869963369964\n",
    "Recall: 0.6598076537767983\n",
    "F1 Score: 0.6540962367049323\n",
    "Matthews Correlation Coefficient (MCC): 0.5866950250269293\n",
    "Cohen's Kappa: 0.5815404571275216\n",
    "Hamming Loss: 0.3168724279835391\n",
    "\n",
    "Confusion Matrix:\n",
    "[[72  9  0  0 12]\n",
    " [ 6 34  5  0  1]\n",
    " [ 3  2 25  0  0]\n",
    " [ 8  0  8 16  0]\n",
    " [ 2 11 10  0 19]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.79      0.77      0.78        93\n",
    "           1       0.61      0.74      0.67        46\n",
    "           2       0.52      0.83      0.64        30\n",
    "           3       1.00      0.50      0.67        32\n",
    "           4       0.59      0.45      0.51        42\n",
    "\n",
    "    accuracy                           0.68       243\n",
    "   macro avg       0.70      0.66      0.65       243\n",
    "weighted avg       0.72      0.68      0.68       243\n",
    "\n",
    "\n",
    "\n",
    "Model: ViT-L/14@336px\n",
    "Model parameters: 427,944,193\n",
    "Input resolution: 336\n",
    "Context length: 77\n",
    "Vocab size: 49408\n",
    "\n",
    "Accuracy: 0.6255144032921811\n",
    "Precision: 0.6483090561920349\n",
    "Recall: 0.5988711347091431\n",
    "F1 Score: 0.5949292342066084\n",
    "Matthews Correlation Coefficient (MCC): 0.5095524392810765\n",
    "Cohen's Kappa: 0.5044483786388185\n",
    "Hamming Loss: 0.37448559670781895\n",
    "\n",
    "Confusion Matrix:\n",
    "[[68 11  1  0 13]\n",
    " [10 29  6  0  1]\n",
    " [ 4  2 23  1  0]\n",
    " [10  0  8 14  0]\n",
    " [ 2  8 14  0 18]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.72      0.73      0.73        93\n",
    "           1       0.58      0.63      0.60        46\n",
    "           2       0.44      0.77      0.56        30\n",
    "           3       0.93      0.44      0.60        32\n",
    "           4       0.56      0.43      0.49        42\n",
    "\n",
    "    accuracy                           0.63       243\n",
    "   macro avg       0.65      0.60      0.59       243\n",
    "weighted avg       0.66      0.63      0.62       243\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
