{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recyclability Classifier, based on OpenAI's CLIP Model\n",
    "Source: https://openai.com/research/clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, matthews_corrcoef, cohen_kappa_score, hamming_loss\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df_dataset = load_from_pickle(dataset_file)\n",
    "# Take 10% of stratified samples for zero-shot classification testing\n",
    "_x_train, zs_x, _y_train, zs_y = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.1, stratify=df_dataset['Material Class'], random_state=9876)\n",
    "# 80-20 Train-Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_dataset['File'], df_dataset['Material Class'], test_size=0.2, stratify=df_dataset['Material Class'], random_state=1234)\n",
    "\n",
    "# Initialise material classes\n",
    "material_classes = [i.lower() for i in material_class_mapping.values()]\n",
    "material_classes[0] = \"anything other than paper, plastic, glass, or metal\"\n",
    "\n",
    "# Preparations for model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "text_prompt = torch.cat([clip.tokenize(f\"photo of an object made of {c}\") for c in material_classes]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RN50\n",
      "Model parameters: 102,007,137\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.459983498349835\n",
      "Precision: 0.5364220929770019\n",
      "Recall: 0.38003848168448484\n",
      "F1 Score: 0.3680587218509033\n",
      "Matthews Correlation Coefficient (MCC): 0.25340113747196713\n",
      "Cohen's Kappa: 0.23193098306528914\n",
      "Hamming Loss: 0.540016501650165\n",
      "\n",
      "Confusion Matrix:\n",
      "[[698 122  77   1  25]\n",
      " [227 173  51   0   6]\n",
      " [127   5 159   7   0]\n",
      " [216   1  61  42   2]\n",
      " [267  26  83   5  43]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.76      0.57       923\n",
      "           1       0.53      0.38      0.44       457\n",
      "           2       0.37      0.53      0.44       298\n",
      "           3       0.76      0.13      0.22       322\n",
      "           4       0.57      0.10      0.17       424\n",
      "\n",
      "    accuracy                           0.46      2424\n",
      "   macro avg       0.54      0.38      0.37      2424\n",
      "weighted avg       0.52      0.46      0.41      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: RN101\n",
      "Model parameters: 119,688,033\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.43853135313531355\n",
      "Precision: 0.5527112807582848\n",
      "Recall: 0.41461532266208617\n",
      "F1 Score: 0.3941133714670186\n",
      "Matthews Correlation Coefficient (MCC): 0.24808290524134521\n",
      "Cohen's Kappa: 0.2311673445189052\n",
      "Hamming Loss: 0.5614686468646864\n",
      "\n",
      "Confusion Matrix:\n",
      "[[569  41 234   6  73]\n",
      " [298  84  69   2   4]\n",
      " [ 57   1 237   3   0]\n",
      " [135   2  88  93   4]\n",
      " [250   7  85   2  80]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.62      0.51       923\n",
      "           1       0.62      0.18      0.28       457\n",
      "           2       0.33      0.80      0.47       298\n",
      "           3       0.88      0.29      0.43       322\n",
      "           4       0.50      0.19      0.27       424\n",
      "\n",
      "    accuracy                           0.44      2424\n",
      "   macro avg       0.55      0.41      0.39      2424\n",
      "weighted avg       0.53      0.44      0.41      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: RN50x4\n",
      "Model parameters: 178,300,601\n",
      "Input resolution: 288\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.4236798679867987\n",
      "Precision: 0.48681441780354745\n",
      "Recall: 0.4645814783022167\n",
      "F1 Score: 0.4189558129951056\n",
      "Matthews Correlation Coefficient (MCC): 0.2785911295413147\n",
      "Cohen's Kappa: 0.267045705425068\n",
      "Hamming Loss: 0.5763201320132013\n",
      "\n",
      "Confusion Matrix:\n",
      "[[265 118 281   3 256]\n",
      " [ 48 339  56   5   9]\n",
      " [ 33   7 244  12   2]\n",
      " [147   4  93  71   7]\n",
      " [149  46 120   1 108]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.29      0.34       923\n",
      "           1       0.66      0.74      0.70       457\n",
      "           2       0.31      0.82      0.45       298\n",
      "           3       0.77      0.22      0.34       322\n",
      "           4       0.28      0.25      0.27       424\n",
      "\n",
      "    accuracy                           0.42      2424\n",
      "   macro avg       0.49      0.46      0.42      2424\n",
      "weighted avg       0.47      0.42      0.41      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: RN50x16\n",
      "Model parameters: 290,979,217\n",
      "Input resolution: 384\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.3778877887788779\n",
      "Precision: 0.6005714234807596\n",
      "Recall: 0.2875830346805791\n",
      "F1 Score: 0.2680951382913359\n",
      "Matthews Correlation Coefficient (MCC): 0.10396886235842223\n",
      "Cohen's Kappa: 0.08371582946158096\n",
      "Hamming Loss: 0.6221122112211221\n",
      "\n",
      "Confusion Matrix:\n",
      "[[672   2 228   2  19]\n",
      " [338  54  51   0  14]\n",
      " [170   0 126   1   1]\n",
      " [276   0  22  24   0]\n",
      " [376   1   6   1  40]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.73      0.49       923\n",
      "           1       0.95      0.12      0.21       457\n",
      "           2       0.29      0.42      0.34       298\n",
      "           3       0.86      0.07      0.14       322\n",
      "           4       0.54      0.09      0.16       424\n",
      "\n",
      "    accuracy                           0.38      2424\n",
      "   macro avg       0.60      0.29      0.27      2424\n",
      "weighted avg       0.56      0.38      0.31      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: RN50x64\n",
      "Model parameters: 623,258,305\n",
      "Input resolution: 448\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.5107260726072608\n",
      "Precision: 0.6150121280504154\n",
      "Recall: 0.503943698798375\n",
      "F1 Score: 0.4940139667238478\n",
      "Matthews Correlation Coefficient (MCC): 0.36780074396645157\n",
      "Cohen's Kappa: 0.3562257593536424\n",
      "Hamming Loss: 0.4892739273927393\n",
      "\n",
      "Confusion Matrix:\n",
      "[[507  92 301   4  19]\n",
      " [ 93 289  71   0   4]\n",
      " [ 60   9 214  15   0]\n",
      " [151   6  54 110   1]\n",
      " [123 126  55   2 118]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.55       923\n",
      "           1       0.55      0.63      0.59       457\n",
      "           2       0.31      0.72      0.43       298\n",
      "           3       0.84      0.34      0.49       322\n",
      "           4       0.83      0.28      0.42       424\n",
      "\n",
      "    accuracy                           0.51      2424\n",
      "   macro avg       0.62      0.50      0.49      2424\n",
      "weighted avg       0.61      0.51      0.51      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: ViT-B/32\n",
      "Model parameters: 151,277,313\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.5198019801980198\n",
      "Precision: 0.5566003027870373\n",
      "Recall: 0.5115291964599042\n",
      "F1 Score: 0.5088150348719772\n",
      "Matthews Correlation Coefficient (MCC): 0.36312681718413553\n",
      "Cohen's Kappa: 0.35875201985422955\n",
      "Hamming Loss: 0.4801980198019802\n",
      "\n",
      "Confusion Matrix:\n",
      "[[515 195 110   0 103]\n",
      " [ 65 308  61   3  20]\n",
      " [ 79  12 191  14   2]\n",
      " [150   2  27 140   3]\n",
      " [190  84  37   7 106]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       923\n",
      "           1       0.51      0.67      0.58       457\n",
      "           2       0.45      0.64      0.53       298\n",
      "           3       0.85      0.43      0.58       322\n",
      "           4       0.45      0.25      0.32       424\n",
      "\n",
      "    accuracy                           0.52      2424\n",
      "   macro avg       0.56      0.51      0.51      2424\n",
      "weighted avg       0.54      0.52      0.51      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: ViT-B/16\n",
      "Model parameters: 149,620,737\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.49834983498349833\n",
      "Precision: 0.5593171334247528\n",
      "Recall: 0.4970808217221248\n",
      "F1 Score: 0.48833988282391905\n",
      "Matthews Correlation Coefficient (MCC): 0.3454062610394499\n",
      "Cohen's Kappa: 0.3408978292174629\n",
      "Hamming Loss: 0.5016501650165016\n",
      "\n",
      "Confusion Matrix:\n",
      "[[483  27  93   0 320]\n",
      " [126 246  68   1  16]\n",
      " [ 48  14 223  10   3]\n",
      " [121   0  97  96   8]\n",
      " [108  97  57   2 160]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.52      0.53       923\n",
      "           1       0.64      0.54      0.59       457\n",
      "           2       0.41      0.75      0.53       298\n",
      "           3       0.88      0.30      0.45       322\n",
      "           4       0.32      0.38      0.34       424\n",
      "\n",
      "    accuracy                           0.50      2424\n",
      "   macro avg       0.56      0.50      0.49      2424\n",
      "weighted avg       0.55      0.50      0.50      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: ViT-L/14\n",
      "Model parameters: 427,616,513\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.6621287128712872\n",
      "Precision: 0.6671066030427073\n",
      "Recall: 0.6464374130645891\n",
      "F1 Score: 0.6345731510632313\n",
      "Matthews Correlation Coefficient (MCC): 0.5628138868486012\n",
      "Cohen's Kappa: 0.557143634710465\n",
      "Hamming Loss: 0.3378712871287129\n",
      "\n",
      "Confusion Matrix:\n",
      "[[683  81  16   2 141]\n",
      " [ 56 334  65   0   2]\n",
      " [ 27  13 246  12   0]\n",
      " [ 72   2  73 173   2]\n",
      " [ 34  82 134   5 169]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       923\n",
      "           1       0.65      0.73      0.69       457\n",
      "           2       0.46      0.83      0.59       298\n",
      "           3       0.90      0.54      0.67       322\n",
      "           4       0.54      0.40      0.46       424\n",
      "\n",
      "    accuracy                           0.66      2424\n",
      "   macro avg       0.67      0.65      0.63      2424\n",
      "weighted avg       0.69      0.66      0.66      2424\n",
      "\n",
      "\n",
      "\n",
      "Model: ViT-L/14@336px\n",
      "Model parameters: 427,944,193\n",
      "Input resolution: 336\n",
      "Context length: 77\n",
      "Vocab size: 49408\n",
      "\n",
      "Accuracy: 0.6542904290429042\n",
      "Precision: 0.663429523779947\n",
      "Recall: 0.627868365041197\n",
      "F1 Score: 0.6192232789472756\n",
      "Matthews Correlation Coefficient (MCC): 0.5501572631477752\n",
      "Cohen's Kappa: 0.5438385557779997\n",
      "Hamming Loss: 0.3457095709570957\n",
      "\n",
      "Confusion Matrix:\n",
      "[[708  82   8   1 124]\n",
      " [ 65 325  65   0   2]\n",
      " [ 36  12 238  12   0]\n",
      " [ 81   2  79 160   0]\n",
      " [ 41  75 150   3 155]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       923\n",
      "           1       0.66      0.71      0.68       457\n",
      "           2       0.44      0.80      0.57       298\n",
      "           3       0.91      0.50      0.64       322\n",
      "           4       0.55      0.37      0.44       424\n",
      "\n",
      "    accuracy                           0.65      2424\n",
      "   macro avg       0.66      0.63      0.62      2424\n",
      "weighted avg       0.68      0.65      0.65      2424\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Zero Shot Classification \"\"\"\n",
    "# Compare performance of available models\n",
    "for current_model in clip.available_models(): \n",
    "    # Initialise model\n",
    "    model, preprocess = clip.load(current_model, device=device, download_root=MODEL_FOLDER)\n",
    "\n",
    "    # Get model specifications\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "    \n",
    "    print(\"Model:\", current_model)\n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    print(\"Input resolution:\", input_resolution)\n",
    "    print(\"Context length:\", context_length)\n",
    "    print(\"Vocab size:\", vocab_size, end='\\n\\n')\n",
    "    \n",
    "    # Initialise predictions\n",
    "    zs_y_pred = []\n",
    "    for current_image in zs_x:\n",
    "        # Initialise image\n",
    "        image = preprocess(Image.open(current_image)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Classify image's material type\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(text_prompt)\n",
    "            \n",
    "            # logits_per_image, logits_per_text = model(image, text_prompt)\n",
    "            # probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "            values, indices = similarity[0].topk(len(material_classes))\n",
    "\n",
    "            # Add result to predictions\n",
    "            zs_y_pred.append(int(indices[0]))\n",
    "\n",
    "            # Print the result\n",
    "            # print(\"\\nTop predictions:\\n\")\n",
    "            # for value, index in zip(values, indices):\n",
    "            #     print(f\"{material_classes[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "\n",
    "    # Get model performance\n",
    "    list_zs_y = list(zs_y)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(list_zs_y, zs_y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(list_zs_y, zs_y_pred, average='macro')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC)\n",
    "    mcc = matthews_corrcoef(list_zs_y, zs_y_pred)\n",
    "    print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(list_zs_y, zs_y_pred)\n",
    "    print(\"Cohen's Kappa:\", kappa)\n",
    "\n",
    "    # Hamming Loss\n",
    "    hamming_loss_val = hamming_loss(list_zs_y, zs_y_pred)\n",
    "    print(\"Hamming Loss:\", hamming_loss_val, end='\\n\\n')\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(list_zs_y, zs_y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm, end=\"\\n\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(list_zs_y, zs_y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report, end=\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
